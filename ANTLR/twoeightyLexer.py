# Generated from twoeighty.g4 by ANTLR 4.5.3
from antlr4 import *
from io import StringIO


def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u0430\ud6d1\u8206\uad2d\u4417\uaef1\u8d80\uaadd\2\34")
        buf.write("\u0085\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
        buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
        buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
        buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
        buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\3\2\3\2\3\3\3\3\3\4\3\4")
        buf.write("\3\4\3\5\3\5\3\6\3\6\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3")
        buf.write("\b\3\b\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\13\3\13\3\f\3\f\3")
        buf.write("\f\3\f\3\f\3\f\3\f\3\r\3\r\3\16\3\16\3\16\3\16\3\16\3")
        buf.write("\17\3\17\3\20\3\20\3\20\3\20\3\21\3\21\3\22\3\22\3\22")
        buf.write("\3\23\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\3\26\3\27")
        buf.write("\3\27\3\30\3\30\3\31\3\31\3\32\3\32\3\33\6\33\u0082\n")
        buf.write("\33\r\33\16\33\u0083\2\2\34\3\3\5\4\7\5\t\6\13\7\r\b\17")
        buf.write("\t\21\n\23\13\25\f\27\r\31\16\33\17\35\20\37\21!\22#\23")
        buf.write("%\24\'\25)\26+\27-\30/\31\61\32\63\33\65\34\3\2\4\3\2")
        buf.write("c|\3\2\62;\u0085\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2")
        buf.write("\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21")
        buf.write("\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2\2\2\31\3")
        buf.write("\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3\2\2")
        buf.write("\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2\2+\3\2")
        buf.write("\2\2\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3\2\2\2\2")
        buf.write("\65\3\2\2\2\3\67\3\2\2\2\59\3\2\2\2\7;\3\2\2\2\t>\3\2")
        buf.write("\2\2\13@\3\2\2\2\rB\3\2\2\2\17F\3\2\2\2\21L\3\2\2\2\23")
        buf.write("Q\3\2\2\2\25S\3\2\2\2\27U\3\2\2\2\31\\\3\2\2\2\33^\3\2")
        buf.write("\2\2\35c\3\2\2\2\37e\3\2\2\2!i\3\2\2\2#k\3\2\2\2%n\3\2")
        buf.write("\2\2\'q\3\2\2\2)s\3\2\2\2+u\3\2\2\2-x\3\2\2\2/z\3\2\2")
        buf.write("\2\61|\3\2\2\2\63~\3\2\2\2\65\u0081\3\2\2\2\678\7=\2\2")
        buf.write("8\4\3\2\2\29:\7?\2\2:\6\3\2\2\2;<\7o\2\2<=\7u\2\2=\b\3")
        buf.write("\2\2\2>?\7u\2\2?\n\3\2\2\2@A\7<\2\2A\f\3\2\2\2BC\7e\2")
        buf.write("\2CD\7n\2\2DE\7t\2\2E\16\3\2\2\2FG\7e\2\2GH\7n\2\2HI\7")
        buf.write("g\2\2IJ\7c\2\2JK\7t\2\2K\20\3\2\2\2LM\7t\2\2MN\7g\2\2")
        buf.write("NO\7e\2\2OP\7v\2\2P\22\3\2\2\2QR\7t\2\2R\24\3\2\2\2ST")
        buf.write("\7.\2\2T\26\3\2\2\2UV\7e\2\2VW\7k\2\2WX\7t\2\2XY\7e\2")
        buf.write("\2YZ\7n\2\2Z[\7g\2\2[\30\3\2\2\2\\]\7e\2\2]\32\3\2\2\2")
        buf.write("^_\7n\2\2_`\7k\2\2`a\7p\2\2ab\7g\2\2b\34\3\2\2\2cd\7n")
        buf.write("\2\2d\36\3\2\2\2ef\7c\2\2fg\7t\2\2gh\7e\2\2h \3\2\2\2")
        buf.write("ij\7c\2\2j\"\3\2\2\2kl\7-\2\2lm\7-\2\2m$\3\2\2\2no\7/")
        buf.write("\2\2op\7/\2\2p&\3\2\2\2qr\7\'\2\2r(\3\2\2\2st\7\61\2\2")
        buf.write("t*\3\2\2\2uv\7\61\2\2vw\7\61\2\2w,\3\2\2\2xy\7,\2\2y.")
        buf.write("\3\2\2\2z{\7-\2\2{\60\3\2\2\2|}\7/\2\2}\62\3\2\2\2~\177")
        buf.write("\t\2\2\2\177\64\3\2\2\2\u0080\u0082\t\3\2\2\u0081\u0080")
        buf.write("\3\2\2\2\u0082\u0083\3\2\2\2\u0083\u0081\3\2\2\2\u0083")
        buf.write("\u0084\3\2\2\2\u0084\66\3\2\2\2\4\2\u0083\2")
        return buf.getvalue()


class twoeightyLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]


    T__0 = 1
    T__1 = 2
    T__2 = 3
    T__3 = 4
    T__4 = 5
    T__5 = 6
    T__6 = 7
    T__7 = 8
    T__8 = 9
    T__9 = 10
    T__10 = 11
    T__11 = 12
    T__12 = 13
    T__13 = 14
    T__14 = 15
    T__15 = 16
    T__16 = 17
    T__17 = 18
    T__18 = 19
    T__19 = 20
    T__20 = 21
    T__21 = 22
    T__22 = 23
    T__23 = 24
    ID = 25
    INT = 26

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "';'", "'='", "'ms'", "'s'", "':'", "'clr'", "'clear'", "'rect'", 
            "'r'", "','", "'circle'", "'c'", "'line'", "'l'", "'arc'", "'a'", 
            "'++'", "'--'", "'%'", "'/'", "'//'", "'*'", "'+'", "'-'" ]

    symbolicNames = [ "<INVALID>",
            "ID", "INT" ]

    ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                  "T__7", "T__8", "T__9", "T__10", "T__11", "T__12", "T__13", 
                  "T__14", "T__15", "T__16", "T__17", "T__18", "T__19", 
                  "T__20", "T__21", "T__22", "T__23", "ID", "INT" ]

    grammarFileName = "twoeighty.g4"

    def __init__(self, input=None):
        super().__init__(input)
        self.checkVersion("4.5.3")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


